{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "from keras import Sequential\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    Conv2DTranspose,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    LeakyReLU,\n",
    "    InputLayer,\n",
    "    Reshape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    depth = 64\n",
    "    model = Sequential(\n",
    "        [\n",
    "            InputLayer((100, 100, 3)),\n",
    "            # Conv 1\n",
    "            Conv2D(depth * 1, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "            LeakyReLU(0.2),\n",
    "            # Conv 2\n",
    "            Conv2D(depth * 2, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "            LeakyReLU(0.2),\n",
    "            # Conv 3\n",
    "            Conv2D(depth * 4, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "            LeakyReLU(0.2),\n",
    "            # Connected\n",
    "            Flatten(),\n",
    "            Dropout(0.25),\n",
    "            Dense(1, activation=\"sigmoid\"),  # output - T or F\n",
    "        ]\n",
    "    )\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "discriminator().summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(latent_dim):\n",
    "  n_nodes = 25 * 25 * 128\n",
    "  model = Sequential([\n",
    "    # 25 x 25 base image\n",
    "    Dense(n_nodes, input_dim=latent_dim),\n",
    "    LeakyReLU(0.2),\n",
    "    Reshape((25, 25, 128)),\n",
    "    # upsample to 50 x 50\n",
    "    Conv2DTranspose(128, (4, 4), strides=(2,2), padding='same'),\n",
    "    LeakyReLU(0.2),\n",
    "    # up sample to 100 x 100\n",
    "    Conv2DTranspose(128, (4, 4), strides=(2,2), padding='same'),\n",
    "    LeakyReLU(0.2),\n",
    "    Conv2D(3, (100, 100), activation='tanh', padding='same'),\n",
    "  ])\n",
    "  return model\n",
    "\n",
    "generator(100).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan(g_model, d_model):\n",
    "  d_model.trainable = False\n",
    "  model = Sequential([\n",
    "    g_model,\n",
    "    d_model,\n",
    "  ])\n",
    "  model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "  return model\n",
    "\n",
    "gan(generator(100), discriminator()).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "\t# choose random instances\n",
    "\tix = np.random.randint(0, dataset.shape[0], n_samples)\n",
    "\t# retrieve selected images\n",
    "\tX = dataset[ix]\n",
    "\t# generate 'real' class labels (1)\n",
    "\ty = np.ones((n_samples, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "\t# generate points in the latent space\n",
    "\tx_input = np.random.randn(latent_dim * n_samples)\n",
    "\t# reshape into a batch of inputs for the network\n",
    "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
    "\treturn x_input\n",
    "\n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
    "\t# generate points in latent space\n",
    "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
    "\t# predict outputs\n",
    "\tX = g_model.predict(x_input)\n",
    "\t# create 'fake' class labels (0)\n",
    "\ty = np.zeros((n_samples, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and save a plot of generated images\n",
    "def save_plot(examples, epoch, n=7):\n",
    "\t# scale from [-1,1] to [0,1]\n",
    "\texamples = (examples + 1) / 2.0\n",
    "\t# plot images\n",
    "\tfor i in range(n * n):\n",
    "\t\t# define subplot\n",
    "\t\tplt.subplot(n, n, 1 + i)\n",
    "\t\t# turn off axis\n",
    "\t\tplt.axis('off')\n",
    "\t\t# plot raw pixel data\n",
    "\t\tplt.imshow(examples[i])\n",
    "\t# save plot to file\n",
    "\tfilename = 'generated_plot_e%03d.png' % (epoch+1)\n",
    "\tplt.savefig(filename)\n",
    "\tplt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the discriminator, plot generated images, save generator model\n",
    "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=150):\n",
    "\t# prepare real samples\n",
    "\tX_real, y_real = generate_real_samples(dataset, n_samples)\n",
    "\t# evaluate discriminator on real examples\n",
    "\t_, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
    "\t# prepare fake examples\n",
    "\tx_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "\t# evaluate discriminator on fake examples\n",
    "\t_, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
    "\t# summarize discriminator performance\n",
    "\tprint('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
    "\t# save plot\n",
    "\tsave_plot(x_fake, epoch)\n",
    "\t# save the generator model tile file\n",
    "\tfilename = 'generator_model_%03d.h5' % (epoch+1)\n",
    "\tg_model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=200, n_batch=128):\n",
    "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "\thalf_batch = int(n_batch / 2)\n",
    "\t# manually enumerate epochs\n",
    "\tfor i in range(n_epochs):\n",
    "\t\t# enumerate batches over the training set\n",
    "\t\tfor j in range(bat_per_epo):\n",
    "\t\t\t# get randomly selected 'real' samples\n",
    "\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "\t\t\t# update discriminator model weights\n",
    "\t\t\td_loss1, _ = d_model.train_on_batch(X_real, y_real)\n",
    "\t\t\t# generate 'fake' examples\n",
    "\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "\t\t\t# update discriminator model weights\n",
    "\t\t\td_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n",
    "\t\t\t# prepare points in latent space as input for the generator\n",
    "\t\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n",
    "\t\t\t# create inverted labels for the fake samples\n",
    "\t\t\ty_gan = np.ones((n_batch, 1))\n",
    "\t\t\t# update the generator via the discriminator's error\n",
    "\t\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "\t\t\t# summarize loss on this batch\n",
    "\t\t\tprint('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n",
    "\t\t\t\t(i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
    "\t\t# evaluate the model performance, sometimes\n",
    "\t\t# if (i+1) % 10 == 0:\n",
    "\t\t\tsummarize_performance(i, g_model, d_model, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "path = \"../Data/Processed_Data/Drake_Hotline_Bling/imgs/\"\n",
    "raw_images = []\n",
    "for i in range(100):\n",
    "    img = cv2.imread(path + f\"{i}.png\")\n",
    "    raw_images.append(img)\n",
    "\n",
    "dataset = np.array(raw_images)\n",
    "print(dataset.min(), dataset.max())\n",
    "\n",
    "scale = lambda x: (x - 127.5) / 127.5\n",
    "dataset = scale(dataset)\n",
    "\n",
    "print(dataset.min(), dataset.max())\n",
    "print(dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "d_model = discriminator()\n",
    "g_model = generator(latent_dim)\n",
    "gan_model = gan(g_model, d_model)\n",
    "train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=5, n_batch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_performance(i, g_model, d_model, dataset, latent_dim)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c12755cee8e934f424469f8443f5f77baf5938e157a9986886e94a8c7c332e37"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
