{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Camouflage10/MEME-GAN/blob/main/GAN/gan_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_ymttSt3x29K"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import cv2\n",
        "from keras import Sequential\n",
        "from keras.layers import (\n",
        "    Dense,\n",
        "    Conv2D,\n",
        "    Conv2DTranspose,\n",
        "    MaxPooling2D,\n",
        "    Flatten,\n",
        "    Dropout,\n",
        "    LeakyReLU,\n",
        "    InputLayer,\n",
        "    Reshape,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RVGkZCG6x29N",
        "outputId": "86984cde-d26f-4d6d-9f01-338340d97ef5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 50, 50, 64)        1792      \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 50, 50, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 25, 25, 128)       73856     \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 25, 25, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 13, 13, 256)       295168    \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 13, 13, 256)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 43264)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 43264)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 43265     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 414,081\n",
            "Trainable params: 414,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def discriminator():\n",
        "    depth = 64\n",
        "    model = Sequential(\n",
        "        [\n",
        "            InputLayer((100, 100, 3)),\n",
        "            # Conv 1\n",
        "            Conv2D(depth * 1, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "            LeakyReLU(0.2),\n",
        "            # Conv 2\n",
        "            Conv2D(depth * 2, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "            LeakyReLU(0.2),\n",
        "            # Conv 3\n",
        "            Conv2D(depth * 4, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "            LeakyReLU(0.2),\n",
        "            # Connected\n",
        "            Flatten(),\n",
        "            Dropout(0.25),\n",
        "            Dense(1, activation=\"sigmoid\"),  # output - T or F\n",
        "        ]\n",
        "    )\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "\n",
        "discriminator().summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ft3D03Hnx29N",
        "outputId": "31217169-d603-4473-afad-df9b87dc58a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 80000)             8080000   \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 80000)             0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 25, 25, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 50, 50, 128)      262272    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 50, 50, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 100, 100, 128)    262272    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 100, 100, 128)     0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 100, 100, 3)       3840003   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,444,547\n",
            "Trainable params: 12,444,547\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def generator(latent_dim):\n",
        "  n_nodes = 25 * 25 * 128\n",
        "  model = Sequential([\n",
        "    # 25 x 25 base image\n",
        "    Dense(n_nodes, input_dim=latent_dim),\n",
        "    LeakyReLU(0.2),\n",
        "    Reshape((25, 25, 128)),\n",
        "    # upsample to 50 x 50\n",
        "    Conv2DTranspose(128, (4, 4), strides=(2,2), padding='same'),\n",
        "    LeakyReLU(0.2),\n",
        "    # up sample to 100 x 100\n",
        "    Conv2DTranspose(128, (4, 4), strides=(2,2), padding='same'),\n",
        "    LeakyReLU(0.2),\n",
        "    Conv2D(3, (100, 100), activation='tanh', padding='same'),\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "generator(100).summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BAlfrpOox29O",
        "outputId": "96fae6c1-d863-4191-9dfb-aca0d6a415d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_2 (Sequential)   (None, 100, 100, 3)       12444547  \n",
            "                                                                 \n",
            " sequential_3 (Sequential)   (None, 1)                 414081    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,858,628\n",
            "Trainable params: 12,444,547\n",
            "Non-trainable params: 414,081\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def gan(g_model, d_model):\n",
        "  d_model.trainable = False\n",
        "  model = Sequential([\n",
        "    g_model,\n",
        "    d_model,\n",
        "  ])\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "  return model\n",
        "\n",
        "gan(generator(100), discriminator()).summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yHsIEkAgx29O"
      },
      "outputs": [],
      "source": [
        "# select real samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "\t# choose random instances\n",
        "\tix = np.random.randint(0, dataset.shape[0], n_samples)\n",
        "\t# retrieve selected images\n",
        "\tX = dataset[ix]\n",
        "\t# generate 'real' class labels (1)\n",
        "\ty = np.ones((n_samples, 1))\n",
        "\treturn X, y\n",
        "\n",
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\t# generate points in the latent space\n",
        "\tx_input = np.random.randn(latent_dim * n_samples)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input\n",
        "\n",
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
        "\t# generate points in latent space\n",
        "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
        "\t# predict outputs\n",
        "\tX = g_model.predict(x_input)\n",
        "\t# create 'fake' class labels (0)\n",
        "\ty = np.zeros((n_samples, 1))\n",
        "\treturn X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bw3PFJzix29P"
      },
      "outputs": [],
      "source": [
        "# create and save a plot of generated images\n",
        "def save_plot(examples, epoch, n=10):\n",
        "\t# scale from [-1,1] to [0,1]\n",
        "\texamples = (examples + 1) / 2.0\n",
        "\t# plot images\n",
        "\tfor i in range(n * n):\n",
        "\t\t# define subplot\n",
        "\t\tplt.subplot(n, n, 1 + i)\n",
        "\t\t# turn off axis\n",
        "\t\tplt.axis('off')\n",
        "\t\t# plot raw pixel data\n",
        "\t\tplt.imshow(examples[i])\n",
        "\t# save plot to file\n",
        "\tfilename = 'generated_plot_e%03d.png' % (epoch+1)\n",
        "\tplt.savefig(filename)\n",
        "\tplt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bhxsOhg_x29Q"
      },
      "outputs": [],
      "source": [
        "# evaluate the discriminator, plot generated images, save generator model\n",
        "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n",
        "\t# prepare real samples\n",
        "\tX_real, y_real = generate_real_samples(dataset, n_samples)\n",
        "\t# evaluate discriminator on real examples\n",
        "\t_, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
        "\t# prepare fake examples\n",
        "\tx_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "\t# evaluate discriminator on fake examples\n",
        "\t_, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
        "\t# summarize discriminator performance\n",
        "\tprint('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
        "\t# save plot\n",
        "\tsave_plot(x_fake, epoch)\n",
        "\t# save the generator model tile file\n",
        "\tfilename = 'generator_model_%03d.h5' % (epoch+1)\n",
        "\tg_model.save(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qHjvEi9jx29Q"
      },
      "outputs": [],
      "source": [
        "# train the generator and discriminator\n",
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=200, n_batch=128):\n",
        "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "\thalf_batch = int(n_batch / 2)\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_epochs):\n",
        "\t\t# enumerate batches over the training set\n",
        "\t\tfor j in range(bat_per_epo):\n",
        "\t\t\t# get randomly selected 'real' samples\n",
        "\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "\t\t\t# update discriminator model weights\n",
        "\t\t\td_loss1, _ = d_model.train_on_batch(X_real, y_real)\n",
        "\t\t\t# generate 'fake' examples\n",
        "\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\t\t\t# update discriminator model weights\n",
        "\t\t\td_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n",
        "\t\t\t# prepare points in latent space as input for the generator\n",
        "\t\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n",
        "\t\t\t# create inverted labels for the fake samples\n",
        "\t\t\ty_gan = np.ones((n_batch, 1))\n",
        "\t\t\t# update the generator via the discriminator's error\n",
        "\t\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "\t\t\t# summarize loss on this batch\n",
        "\t\t\tprint('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n",
        "\t\t\t\t(i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
        "\t\t# evaluate the model performance, sometimes\n",
        "\t\t# if (i+1) % 10 == 0:\n",
        "\t\t\tsummarize_performance(i, g_model, d_model, dataset, latent_dim)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NJvWQDddx-f0",
        "outputId": "a9cb401e-06a0-405e-d5de-5d38c746392b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9zak7c6bx29R",
        "outputId": "c4e30239-a0f7-4478-9383-78ed9e30dcd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 255\n",
            "-1.0 1.0\n",
            "(536, 100, 100, 3)\n"
          ]
        }
      ],
      "source": [
        "# load dataset\n",
        "# path = \"../Data/Processed_Data/Drake_Hotline_Bling/imgs/\"\n",
        "path = '/content/drive/MyDrive/GAN_Data/Drake_Hotline_Bling/imgs/'\n",
        "raw_images = []\n",
        "for filename in os.listdir(path):\n",
        "    img = cv2.imread(path + filename)\n",
        "    raw_images.append(img)\n",
        "\n",
        "dataset = np.array(raw_images)\n",
        "print(dataset.min(), dataset.max())\n",
        "\n",
        "scale = lambda x: (x - 127.5) / 127.5\n",
        "dataset = scale(dataset)\n",
        "\n",
        "print(dataset.min(), dataset.max())\n",
        "print(dataset.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name)"
      ],
      "metadata": {
        "id": "Wq7qitoxzK2c",
        "outputId": "ac4c735a-e6c5-48de-fb45-b520a5d6eb37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCpjgPp3x29R"
      },
      "outputs": [],
      "source": [
        "latent_dim = 100\n",
        "d_model = discriminator()\n",
        "g_model = generator(latent_dim)\n",
        "gan_model = gan(g_model, d_model)\n",
        "train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=5, n_batch=25)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "c12755cee8e934f424469f8443f5f77baf5938e157a9986886e94a8c7c332e37"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Copy of gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}